# Наблюдаемость, основные принципы.

Для обеспечения наблюдаемости системы нужны следующие компоненты:
- Метрики
- Логи
- Трейсинг

## Метрики.
Основные метрики, которые надо смотреть у приложения (сервиса):
- Потребление памяти
- Потребление CPU
- Потребление памяти основными API
- Время выполнения основных важных API

Инструменты:
- Prometheus (хранение метрик)
- Grafana (отображение графиков по метрикам)
- cadvisor (метрики контейнеров docker - cpu, память)
- nginxlog-exporter - метрики на основе анализа логов nginx
    - время выполнения конкретных запросов
    - статус ответов

Для построения различных метрик можно использовать:
- Счетчик (counter) - постоянно увеличивающееся значение, подходит например для подсчета количества вызовов
- Измеритель (gauge) - возвращает текущие значение какого-либо параметра, например подходит для получения значения использования памяти
- Гистограмма (histogram) - используется для вычисления процентиля какой-либо метрики, например 95% запросов использовали меньше 300мб памяти

Примеры полезных запросов в grafana:
- Подсчет RPS (из nginxlog-exporter):
  sum(rate(nginx_http_response_count_total{request_uri!="", request_uri!~"^/_wdt.*"}[1m])) by (request_uri)
- Использование CPU контейнерами (из cadvisor):
  sum(rate(container_cpu_usage_seconds_total{name=~"task_tracker.*"}[1m])) by (name)  /
  scalar(engine_daemon_engine_cpus_cpus) * 100
- Потребление памяти контейнерами (из cadvisor):
  sum(container_memory_usage_bytes{name!=""}) by (name)
- Потребление памяти запросом API (gauge из кода):
  max(avg_over_time(task_tracker_php_memory_peak_usage{endpoint!="", endpoint !~ "/_wdt.*"}[1m])) by (endpoint)

Дополнительно можно собрать:
- Количество 500 и 200 ответов, чтобы увидеть все ли ок в целом
- Количество активных воркеров при работе с rabbitmq
- Бизнес метрики

## Логи.
Для логов используем graylog. Надо настроить input, index, stream для запуска.
Из кода логируем нужные этапы выполнения.
Логи можно использовать также в качестве данных для grafana.
По trace_id из трассировки можно связать логи из разных сервисов в единый флоу процесса.

## Трассировка
- Можно использовать параметр trace-id, чтобы при логировании связать цепочку логов в единый поток выполнения
- Использовать инструменты трассировки (Jaeger) - он может наглядно показать путь выполнения запроса и скорость, с которой это было сделано. Чем то похоже на профилирование, только в рамках всей системы.
В Jaeger пишем трассировку процессов - что вызывалось, сколько вызывалось, что-то вроде логирования времени выполнения блоков кода, бенчмарки.